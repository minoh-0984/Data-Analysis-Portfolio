{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Collection\n",
    "Collecting Data Using APIs\n",
    "The HTTP protocol allows you to send and receive information through the web including webpages, images, and other web resources.\n",
    "\n",
    "Uniform resource locator(URL): the most popular way to find resources on the web\n",
    "\n",
    "Scheme: http://\n",
    "Internet address or Base URL: www.ibm.com\n",
    "Route location on the web server: /images/IDSNlogo.png\n",
    "Request\n",
    "\n",
    "Request start line = GET method + location of the resource /index.html + HTTP version\n",
    "Request header passes additional information with an HTTP request\n",
    "Response\n",
    "\n",
    "Response start line = version number HTTP/1.0 + a status code (200) meaning success, + a descriptive phrase (OK).\n",
    "Response header contains useful information\n",
    "Response body containing the requested file an HTML document\n",
    "Requests in Python\n",
    "\n",
    "import requests\n",
    "import os \n",
    "from PIL import Image\n",
    "from IPython.display import IFrame\n",
    "#GET request //# Use single quotation marks for defining string\n",
    "url='https://www.ibm.com/'  \n",
    "r=requests.get(url)\n",
    "#status of the request\n",
    "r.status_code  \n",
    "#view request headers //r.request.body\n",
    "print(r.request.headers)  \n",
    "#HTTP response header\n",
    "header=r.headers  \n",
    "#obtain the date\n",
    "header['date']  \n",
    "#obtain the type of data\n",
    "header['Content-Type']  \n",
    "r.encoding\n",
    "#view text\n",
    "r.text[0:100]  \n",
    "#write content(image)\n",
    "path=os.path.join(os.getcwd(),'image.png')\n",
    "with open(path,'wb') as f:\n",
    "    f.write(r.content)\n",
    "Image.open(path)\n",
    "Get Request with URL Parameters\n",
    "\n",
    "You can use the GET method to modify the results of your query\n",
    "url_get='http://httpbin.org/get'\n",
    "#To create a Query string, add a dictionary.\n",
    "payload={\"name\":\"Joseph\",\"ID\":\"123\"}  \n",
    "r=requests.get(url_get,params=payload)\n",
    "r.url  #'http://httpbin.org/get?name=Joseph&ID=123'\n",
    "#key args in JSON format\n",
    "r.json()['args']  \n",
    "Post Requests\n",
    "\n",
    "the POST request sends the data in a request body\n",
    "url_post='http://httpbin.org/post'\n",
    "r_post=requests.post(url_post,data=payload)\n",
    "r_post.url \n",
    "r_post.request.body\n",
    "r_post.json()['form']\n",
    "Collecting Data Using Webscraping\n",
    "Review of Webscraping\n",
    "\n",
    "from bs4 import BeautifulSoup  # this module helps in web scrapping.\n",
    "import requests  # this module helps us to download a web page\n",
    "url = \"http://www.ibm.com\"\n",
    "# get the contents of the webpage in text format and store in a variable called data\n",
    "data  = requests.get(url).text  \n",
    "# create a soup object using the variable 'data'\n",
    "soup = BeautifulSoup(data,\"html5lib\")  \n",
    "# in html anchor/link is represented by the tag <a>\n",
    "for link in soup.find_all('a'):  \n",
    "    print(link.get('href'))\n",
    "# in html image is represented by the tag <img>\n",
    "for link in soup.find_all('img'):\n",
    "    print(link.get('src'))\n",
    "Scrape data from html table\n",
    "\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/HTMLColorCodes.html\"\n",
    "# get the contents of the webpage in text format and store in a variable called data\n",
    "data  = requests.get(url).text  \n",
    "soup = BeautifulSoup(data,\"html5lib\")\n",
    "# in html table is represented by the tag <table>\n",
    "table = soup.find('table') \n",
    "# in html table row is represented by the tag <tr>\n",
    "for row in table.find_all('tr'): \n",
    "    # in html a column is represented by the tag <td>\n",
    "    cols = row.find_all('td') \n",
    "    # store the value in column 3 as color_name\n",
    "    color_name = cols[2].getText() \n",
    "    # store the value in column 4 as color_code\n",
    "    color_code = cols[3].getText() \n",
    "    print(\"{}--->{}\".format(color_name,color_code))\n",
    "Exploring Data\n",
    "Load the dataset\n",
    "\n",
    "import pandas as pd\n",
    "dataset_url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\"\n",
    "df = pd.read_csv(dataset_url)\n",
    "Explore the dataset\n",
    "\n",
    "#Display the top & bottom 5 rows and columns from your dataset\n",
    "df.head()  \n",
    "df.tail()\n",
    "#The number of rows in the dataset.\n",
    "df.shape[0]  \n",
    "#The number of columns in the dataset.\n",
    "df.shape[1]  \n",
    "#Print the datatype of all columns.\n",
    "df.dtypes  \n",
    "#Print the mean age of the survey participants.\n",
    "df[\"Age\"].mean()\n",
    "#Print how many unique countries are there in the Country column.\n",
    "df[\"Country\"].nunique()  \n",
    "Data Wrangling\n",
    "Load the dataset\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m1_survey_data.csv\")\n",
    "Finding Duplicates\n",
    "\n",
    "#Find how many duplicate rows exist in the dataframe.\n",
    "df.duplicated(keep='first').sum()  \n",
    "#Show duplicated rows\n",
    "duplicateRows = df[df.duplicated()]  \n",
    "duplicateRows  \n",
    "#numbers of duplicate values in the column Respondent\n",
    "df[\"Respondent\"].duplicated(keep='first').sum()  \n",
    "Removing Duplicates\n",
    "\n",
    "#Remove the duplicate rows from the dataframe.\n",
    "df.drop_duplicates(ignore_index=True, inplace=True)  \n",
    "#Verify if duplicates were actually dropped.\n",
    "df.duplicated(keep='first').sum()  \n",
    "#number of rows and columns left\n",
    "df.shape  \n",
    "#numbers of unique rows left in the column Respondent\n",
    "df[\"Respondent\"].nunique  \n",
    "Finding Missing Values\n",
    "\n",
    "#Find the missing values for all columns.\n",
    "df.isnull().sum()  \n",
    "#Find out how many rows are missing in the column EdLevel\n",
    "df[\"EdLevel\"].isnull().sum()  \n",
    "Determine Missing Values\n",
    "\n",
    "#Find the value counts for the column WorkLoc.\n",
    "df[\"WorkLoc\"].value_counts()  \n",
    "#Impute (replace) all the empty rows in the column WorkLoc with the value that you have identified as majority.\n",
    "df[\"WorkLoc\"].fillna(value=\"Office\",inplace=True)  \n",
    "#After imputation there should ideally not be any empty rows in the WorkLoc column.\n",
    "df[\"WorkLoc\"].isnull().sum()  \n",
    "Normalizing Data\n",
    "\n",
    "#List out the various categories in the column 'CompFreq'\n",
    "df[\"CompFreq\"].unique()  \n",
    "#If the CompFreq is Yearly then use the exising value in CompTotal\n",
    "df[\"CompFreq\"].replace(to_replace=\"Yearly\",value=1,inplace=True)  \n",
    "#If the CompFreq is Monthly then multiply the value in CompTotal with 12 (months in an year)\n",
    "df[\"CompFreq\"].replace(to_replace=\"Monthly\",value=12,inplace=True)  \n",
    "#If the CompFreq is Weekly then multiply the value in CompTotal with 52 (weeks in an year)\n",
    "df[\"CompFreq\"].replace(to_replace=\"Weekly\",value=52,inplace=True)  \n",
    "df[\"CompFreq\"].unique()\n",
    "df[\"CompFreq\"].value_counts()\n",
    "#it makes comparison of salaries easy.\n",
    "df['NormalizedAnnualCompensation'] = df[\"CompTotal\"] * df[\"CompFreq\"]  \n",
    "df[\"Respondent\"].nunique()\n",
    "df[\"ConvertedComp\"].describe()\n",
    "df[\"ConvertedComp\"].hist(figsize=(15,4))\n",
    "df['NormalizedAnnualCompensation'].median()\n",
    "Exploratory Data Analysis\n",
    "Import necessary modules\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m2_survey_data.csv\")\n",
    "Distribution: Determine how the data is distributed\n",
    "\n",
    "  #Plot the distribution curve for the column ConvertedComp\n",
    "  plt.figure(figsize=(10,5))\n",
    "  sns.distplot(a=df[\"ConvertedComp\"],bins=20,hist=False)\n",
    "  plt.show()\n",
    "  #Plot the histogram for the column ConvertedComp\n",
    "  plt.figure(figsize=(10,5))\n",
    "  sns.distplot(a=df[\"ConvertedComp\"],bins=20,kde=False)\n",
    "  plt.show()\n",
    "  #the median of the column ConvertedComp\n",
    "  df[\"ConvertedComp\"].median()\n",
    "  #number of responders identified themselves only as a Man\n",
    "  df[\"Gender\"].value_counts()\n",
    "  #the median number of ConvertedComp of responders identified themselves only as a Woman\n",
    "  woman = df[df[\"Gender\"] == \"Woman\"]\n",
    "  woman[\"ConvertedComp\"].median()\n",
    "  #five number summary for the column Age\n",
    "  df[\"Age\"].describe()\n",
    "Outliers\n",
    "\n",
    "#Find out if outliers exist in the column ConvertedComp using a box plot\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(x=df.ConvertedComp, data=df)\n",
    "plt.show()\n",
    "#Find out the Inter Quartile Range for the column ConvertedComp\n",
    "df[\"ConvertedComp\"].describe()\n",
    "#Find out the upper and lower bounds.\n",
    "Q1 = df[\"ConvertedComp\"].quantile(0.25)\n",
    "Q3 = df[\"ConvertedComp\"].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "print(IQR)\n",
    "#Identify how many outliers are there in the ConvertedComp column\n",
    "outliers = (df[\"ConvertedComp\"] < (Q1 - 1.5 * IQR)) | (df[\"ConvertedComp\"] > (Q3 + 1.5 * IQR))\n",
    "outliers.value_counts()\n",
    "less = (df[\"ConvertedComp\"] < (Q1 - 1.5 * IQR))\n",
    "less.value_counts()\n",
    "more = (df[\"ConvertedComp\"] > (Q3 + 1.5 * IQR))\n",
    "more.value_counts()\n",
    "#Create a new dataframe by removing the outliers from the ConvertedComp column\n",
    "RemoveConvertedcomp = df[~(df[\"ConvertedComp\"] > (Q3 + 1.5 * IQR))]\n",
    "RemoveConvertedcomp.head()\n",
    "RemoveConvertedcomp[\"ConvertedComp\"].median()\n",
    "RemoveConvertedcomp[\"ConvertedComp\"].mean()\n",
    "Correlation: Find the correlation between all numerical columns\n",
    "\n",
    "df.corr()\n",
    "Data Visualization\n",
    "Work with Database\n",
    "\n",
    "!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/LargeData/m4_survey_data.sqlite\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "# open a database connection\n",
    "conn = sqlite3.connect(\"m4_survey_data.sqlite\") \n",
    "# print how many rows are there in the table named 'master'\n",
    "QUERY = \"\"\"\n",
    "SELECT COUNT(*)\n",
    "FROM master\n",
    "\"\"\"\n",
    "# the read_sql_query runs the sql query and returns the data as a dataframe\n",
    "df = pd.read_sql_query(QUERY,conn)\n",
    "df.head()\n",
    "# print all the tables names in the database\n",
    "QUERY = \"\"\"\n",
    "SELECT name as Table_Name FROM\n",
    "sqlite_master WHERE\n",
    "type = 'table'\n",
    "\"\"\"\n",
    "# the read_sql_query runs the sql query and returns the data as a dataframe\n",
    "pd.read_sql_query(QUERY,conn)\n",
    "#run a group by query\n",
    "QUERY = \"\"\"\n",
    "SELECT Age,COUNT(*) as count\n",
    "FROM master\n",
    "group by age\n",
    "order by age\n",
    "\"\"\"\n",
    "pd.read_sql_query(QUERY,conn)\n",
    "#Describe a table\n",
    "table_name = 'master'  # the table you wish to describe\n",
    "QUERY = \"\"\"\n",
    "SELECT sql FROM sqlite_master\n",
    "WHERE name= '{}'\n",
    "\"\"\".format(table_name)\n",
    "df = pd.read_sql_query(QUERY,conn)\n",
    "print(df.iat[0,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
